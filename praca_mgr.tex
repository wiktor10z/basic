\documentclass{pracamgr}
\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[pdftex]{graphicx}
\usepackage{multicol}

\author{Wiktor Zuba}

\nralbumu{320501}

\title{Metody ulepszania systemów rekomendacyjnych}

\tytulang{Methods of recommendation systems improving}

\kierunek{Matematyka}

\opiekun{prof. Hung Son Nguyen\\
Instytut Informatyki}

\date{??? 2016}

\dziedzina{ 
11.0 Matematyka, Informatyka:?????????????????????????\\
11.2 Statystyka??????????????????\\
11.4 Sztuczna inteligencja????????????\\ 
}


\klasyfikacja{62-XX Statistics??????????????????????????????\\
68-XX Computer science????????????????????????????????????\\
}

\keywords{???????????????????????}



\begin{document}
\maketitle

\begin{abstract}
???????????????????????????????????????
\end{abstract}


\tableofcontents

\chapter*{Wprowadzenie}
\addcontentsline{toc}{chapter}{Wprowadzenie}


 \chapter{Sformułowanie problemu}
  W każdym modelu danych wykorzystywanym do wyliczania możliwych ocen przedmiotów lub sporządzania list rekomendacji
  występują użytkownicy i przedmioty, oraz pewne niepełne informacje na temat ich powiązań ze sobą.
  Aby móc przewidzieć czy dany nie oceniony jeszcze przedmiot zainteresuje konkretnego użytkownika trzeba dla obu określić preferencje na podstawie 
  załączonych opisów, znanych interakcji tego użytkownika z innymi przedmiotami i przedmiotu z innymi użytkownikami, lub też obu informacji na raz.
  
  
  \section{Podstawowe definicje}
   \textbf{Definicja 1.1.1.} Użytkownik -- osoba korzystająca z serwisu, dla której staramy się stworzyć rekomendacje lub też,
    która tylko dostarcza informacji użytecznych przy ich sporządzaniu dla innych użytkowników.\newline\newline
   %
   \textbf{Definicja 1.1.2.} Przedmiot -- rzecz która jest używana (czasem też oceniana) przez użytkowników.\newline
   
    Przedmiot musi być reużywalny (np. filmy do oglądnięcia, książki do przeczytania, strony internetowe do odwiedzenia),
    lub występujący w wielu identycznych egzemplarzach (przedmioty w sklepach), aby użycie przez innego użytkownika nie wyczerpało jego zasobu
    (wtedy rekomendacja nie miała by sensu, skoro przedmiot nie istnieje) i dało miarodajne informacje na jego temat.
    Przedmiot jest rzeczą, której ocenę przez użytkownika chcemy przewidzieć, lub którą chcemy mu zarekomendować.\newline\newline
   %
   \textbf{Definicja 1.1.3.} Użycie przedmiotu -- zarejestrowana informacja o interakcji użytkownika z przedmiotem,
   dostępna w danych wykorzystywanych do tworzenia rekomendacji -- niekoniecznie prawdziwe używanie przedmiotu
   (kupienie produktu nie oznacza jego używania a wypożyczenie książki jej przeczytania). \newline\newline
   %
   \textbf{Definicja 1.1.4.} Informacja explicite -- wyraźne informacje dostarczone przez użytkownika odnośnie przedmiotu -- głównie
    ocena, recenzja lub przypisanie tagów.\newline\newline
   %
   \textbf{Definicja 1.1.5.} Informacja implicite -- bezwarunkowe informacje o użyciu przedmiotu przez użytkownika
    (kupienie towaru, obejrzenie filmu, wypożyczenie książki, odwiedzenie strony).\newline
    
    Informacje bezwarunkowe, których główną zaletą jest łatwość ich zbierania
    (dzieje się to automatycznie, bez dodatkowych akcji ze strony użytkownika, a czasem i bez jego wiedzy),
    są niestety bardzo narażone na przekłamania odnośnie preferencji użytkownika.
    Po pierwsze zarejestrowanie uzycia przez system wcale nie musi oznaczać faktycznego użycia
    (przypadkowe kliknięcie linku, pomyłka we wpisywaniu nazwy, zrezygnowanie po przeczytaniu opisu), 
    a po drugie z użycia nie musi wynikać pozytywny odbiór.
    W szczególności użycie przedmiotu wynikające z nietrafionych rekomendacji może pogłębiać zawodność systemu.
    Pomimo licznych wad informacje implicite często są jedynymi posiadanymi, a nawet przy dostępnych danych explicite ze względu na
    znacznie większą ilość znajdują istotne zastosowanie w systemach rekomendacyjnych.
    Dane o wielokrotnym użyciu przedmiotu są często spłaszczone do binarnych (przedmiot użyty/nie użyty),
    co pozwala na zmniejsznie rozmiaru pamięci potrzebnej do ich przechowywania, oraz użycie niektórych metod rekomendacji.\newline\newline
   %
   \textbf{Definicja 1.1.6.} Lista rekomendacji -- (zazwyczaj uporządkowany) podzbiór przedmiotów nie użytych dotychczas przez użytkownika,
    które powinny się mu spodobać (być najwyżej ocenione, chętnie użyte).
    
  \section{Przeznaczenie systemów}
   Istnieją dwa główne cele postawione przed systemami rekomendacyjnymi:
   \begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
    \item zbudowanie listy rekomendacyjnej konkretnej długości
    \item przewidzenie niewprowadzonych ocen przedmiotów
   \end{itemize}
   Oczywiście jeżeli system przewidzi oceny wszystkich nieocenionych przedmiotów,
   łatwo można je uszeregować malejąco i obciąć listę w odpowiednim miejscu otrzymując listę rekomendacji pożądanej długości.\newline
   Konwersja w drugą stronę jest znacznie trudniejsza, a bez dodatkowych informacji praktycznie niemożliwa.\newline
   Posiadanie przewidzianych ocen przedmiotów może być bardzo przydatne -- serwis proponujący przedmioty może przedstawiać użytkownikowi
   rekomendacje mocniejsze i słabsze w inny sposób, lub też obciąć listę rekomendacji tylko do przedmiotów o przewidzianej ocenie powyżej pewnego poziomu.
   Dodatkową motywacją do wyliczenia przewidywanych ocen jest możliwość podania tych informacji użytkownikowi wraz z rekomendacjami
   dla mocniejszego zainteresowania użytkownika przedmiotem, oraz zwiększenia satysfakcji z systemu.\newline
   Niestety w niektórych przypadkach na przykład przy posiadaniu jedynie informacji implicite określenie ocen przedmiotów jest niemożliwe
   (chyba że wprowadzimy sztuczne oceny na podstawie miejsc w liście rankingowej). Dodatkowo algorytm generowania rekomendacji którego wynikiem
   jest tylko lista rekomendacji (bez ocen) może posiadać pożądane przez nas zalety jak szybkość lub oszczędność pamięci,
   są więc one wykorzystywane w sytuacjach w których posiadanie przewidzianych ewaluacji nie ma dodatkowych zastosowań.
   
   
   
  \section{Problemy stojące przed systemami rekomendacyjnymi}
   Do czysto teoretycznych badań wykorzystuje się stabilne, nie zmieniające się dane aby uzyskać wiarygodne porównanie jakości algorytmów
   (również pomiedzy niezależnymi badaczami). W danych tych zazwyczaj nie występują skrajne warunki ani błędne informacje,
   ze względu na ciężkość porównania prędkości (badacze uzywają innego sprzętu do badań),
   algorytmy porównywane są głównie pod względem trafności ocen czy rekomendacji.\newline
   W warunkach w których systemy rekomendacyjne są najczęściej wykorzystywane -- systemach proponujących różne rzeczy w internecie dane ulegają ciągłym zmianom
   oznacza to, że nie tylko mogą pojawić się różne nieregularne sytuacje, ale również cały rozkład danych może się zmienić po dłuższym czasie.
   Do głównych problemów jakie mogą napotkać systemy należą:
   \begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
    \item zjawisko zimnego startu -- pojawienie się nowego użytkownika lub przedmiotu.\newline
      Gdy użytkownik nie zdążył użyć wystarczająco wielu przedmiotów i nie załączył o sobie dodatkowych informacji,
      większość algorytmów nie jest w stanie określić jego upodobań.
      W przypadku gdy użytkownik nie użył żadnego przedmiotu nie istnieje wręcz możliwość stworzenia spersonalizowanej rekomendacji
    \item dylemat hipstera -- niektórzy użytkownicy (czasem umyślnie) nie wpasowują się w żadne proste schematy --
     nie są podobni do żadnego innego użytkownika (do zbyt małej ilości dla niektórych algorytmów bazujących na tym podobieństwie).\newline
     Użytkownicy tacy wybierają rzadko używane przez ogół przedmioty, co tworzy jednocześnie w danych przedmioty, które mimo dostatecznej liczby użyć,
     by przekroczyć limity zabezpieczające algorytmy przed sytuacjami trudnymi nie dają się zaklasyfikować odpowiednio.
     Osobie która niejako działa przeciwko systemowi rekomendacyjnemu ciężko przyporządkować trafne propozycje.
     Dopasowanie parametrów algorytmu tak, żeby zoptymalizować funkcje miary jakości,
     obejmujące tych użytkowników może wpłynąć negatywnie również na rekomendacje dla standardowych użytkowników na normalnych przedmiotach.
    \item asymetria pomiedzy ilością przedmiotów ocenionych przez użytkowników -- w przypadku danych explicite często zachodzi sytuacja,
     gdy kilku aktywnych użytkowników wystawia dużo ocen, zaś reszta zaledwie pojedyncze.\newline
     W takiej sytuacji program rekomendujący również powinien być w stanie przydzielić propozycje mniej aktywnym użytownikom.
     Zasadniczym problemem w takiej sytuacji jest to, że ocena jakości w niektórych (zazwyczaj dobrych)
     miarach może być zawyżona przy dobrym dopasowaniu się do tych pojedynczych użytkowników,
     jendocześnie przypasowującej mniej aktywnym oceny bliskie losowym. % może podać/rozrysować przykład
    \item sytuacja w której nie da się już nic zaproponować -- jeśli użytkownik użył znaczną ilość przedmiotów,
     system nie może nic zaproponować albo ponieważ nie ma już wystarczająco dużo przedmiotów nieużytych,
     albo wszystkie pozostałe zostały zaklasyfikowane jako silnie niepasujące.\newline
     Sytuacja ta jest dosyć łatwa do kontrolowania, jednak należy o niej pamiętać przy projektowaniu algorytmu i jego ocenie.
    %.... może jeszcze da się coś wymyślić    
   \end{itemize}
  %\section{Cechy produkcyjnych systemów}
   Poza odpornością na wyżej wymienione sytuacje systemy używane przez ludzi powinny posiadać dodatkowe cechy zapewniające wygodę użycia.
   Podstawową różnicą między badaniem laboratoryjnym a systemem używanym przez ludzi jest szybkość użycia --
   użytkownik portalu internetowego nie jest skłonny czekać aż algorytm używany w rekomendacji przeanalizuje pełną bazę danych od początku
   (może to trwać od kilku minut do wielu godzin).
   Jednym z rozwiązań mogłoby być wyprodukowanie rekomendacji dla wszystkich użytkowników i pamiętanie ich dodatkowo w bazie danych
   jednak wymagałoby to przeliczania od początku po wprowadzeniu kilku zmian, oraz nie dałoby szybkich rozwiązań nowym użytkownikom.
   W takich sytuacjach niektóre systemy mają możliwość przetworzenia danych i stworzenia modelu,
   który pozwoli wyprodukować rekomendacje wystarczająco szybko, a dodatkowo daje możliwość przypasowania nowego użytkownika w krótkim czasie.
   Niektóre algorytmy pozwalają jednak na bardzo szybkie modyfikacje modelu.
   Jeżeli jednak przetworzenie modelu zajmuje zbyt dużo czasu można pamiętać stary model,
   a po pewnej ilości zmian w bazie danych przeliczyć nowy model (nie zaburzając pracy portalu),
   Dodatkowymi zaletami takiego rozwiązania jest łatwa przenośność, oraz rozpraszalność systemu (mały model może być przechowywany w wielu miejscach,
   podczas gdy pełna baza danych znajduje się tylko w jednym).
   
   
   
   %TODO napisać w założeniach, że przy podobieństwie przedmiotów nie chcemy wykluczania podobnych - jak przy sprzętach, tylko chęć użycia nowego innego, ale podobnego
   
   
   


 \chapter{Podstawowe techniki}
  \section{Techniki niespersonalizowane}
   Najprostszą możliwą techniką tworzenia list rekomendacji jest stworzenie pojedynczej liczby najlepszych przedmiotów
   i jako rekomendacji zwrócenie użytkownikowi jej podlisty przedmiotów, których jeszcze nie użył.
   Wartością szeregującą przedmioty może być średnia ocen, popularność lub dowolna inna funkcja monotoniczna ze względu na oceny wystawione przedmiotowi.
   Główną wadą takiego podejścia jest to, ze tylko niewielki podzbiór popularnych przedmiotów zostanie zaproponowany ogółowi użytkowników,
   co pogłębi różnicę w popularności przedmiotów (przedmiot, który mógłby spodobać się użytkownikom nie będzie proponowany dlatego, że za mało osób go zna).
   Analogicznie, jako że gusta użytkowników są różne przedmiot oceniany jako dobry może obniżyć swoją średnią ponieważ będzie proponowany osobom do których nie pasuje,
   co może zaburzyć obraz danych.\newline
   Pomimo swoich wad niespersonalizowane rekomendacje oprócz dobrego punktu odniesienia stanowią jedyny sposób przydziału rekomendacji nowym użytkownikom
   (brak opisu i za mało użytych przedmiotów by zastosować ine algorytmy).
   Cecha ta powoduje, że często stanowią one fragment innych algorytmów używany w skrajnych przypadkach. 
  \section{Filtrowanie kolaboratywne}%TODO napisać, że raczej explicit feedback, choć dla implicit feedback też coś się da
   Jedną z najbardziej podstawowych technik przewidywania ocen przedmiotów jest filtrowanie kolaboratywne polegające na wykorzystaniu wyłącznie informacji
   o użyciach przedmiotów (bez jawnych informacji o użytkownikach, czy przedmiotach). Predykcje tworzone są na podstawie założenia, że użytkownicy,
   którzy używali wych samych przedmiotów i podobnie je ocenili mają te same upodobania. Jeżeli ustali się na podstawie wspólnie ocenionych przedmiotów,
   że dwóch użytkowników jest bardzo podobnych można założyć,
   że przedmioty użyte tylko przez jednego z nich byłyby podobnie ocenione i przez drugiego.
   %TODO może jakieś gładkie przejście z opisu do algorytmów
   \subsection{Colaborative Filtering}
   Najprostszym algorytmem realizującym ideę filtorwania kolaboratywnego jest zdefiniowanie funkcji podobieństwa pomiędzy użytkownikami
   oraz wystawienie przedmiotowi oceny jako pewnej średniej z ocen najbardziej podobnych użytkowników, którzy ten przedmiot ocenili.\newline
   Do najpowszechniej stosowanych funkcji podobieństwa należą:
   \begin{itemize}\itemsep1pt \parskip0pt \parsep0pt
    \item Współczynnik korelacji liniowej Paersona:
     \begin{center}
      $S_{uv}=\frac{\sum\limits_{i\in R_{uv}}(r_{ui}-\overline{r_u})(r_{vi}-\overline{r_v})}
      {\sqrt{\sum\limits_{i\in R_{uv}}(r_{ui}-\overline{r_u})^2\sum\limits_{i\in R_{uv}}(r_{vi}-\overline{r_v})^2}}$
     \end{center}
     Wyliczane dla par użytkowników, którzy ocenili po conajmniej dwa przedmioty, w tym conajmniej jeden wspólny.
    \item podobieństwo kosinusowe:
     \begin{center}
      $S_{uv}=\frac{\sum\limits_{i\in R_{uv}}r_{ui}\cdot r_{vi}}
      {\sqrt{\sum\limits_{i\in R_{uv}}r_{ui}^2\sum\limits_{i\in R_{uv}}r_{vi}^2}}$
     \end{center}
     Wyliczane dla par użytkowników, którzy ocenili conajmniej jeden wspólny przedmiot.
    %\item podobieństwo implicite\newline % jak się nazywa przecięcie przez suma - odpowiednik f-score
     %begin{center}
      %$S_{uv}=\frac{|R_{uv}|}{|R_{u}\cup R_{v}|}$\newline
      %Używane gdy dostępne są jedynie informacje implicite.
     %end{center} 
   \end{itemize}
   {\scriptsize
   $S_{u,v}$ -- podobieństwo użytkowników $u$ i $v$, $R_{uv}$ -- zbiór przedmiotów, które ocenili zarówno użytkownik $u$ jak i $v$,\newline
   $r_{ui}$ -- ocena przedmiotu $i$ wystawiona przez użytkownika $u$, $\overline{r_{u}}$ -- średnia ocen wystawionych przez użytkownika $u$
   %,\newline$R_{u}$ -- zbiór przedmiotów, ocenionych przez użytkownika $u$
   }\newline
   Najczęściej stosowany jest współczynnik korelacji Paersona, jako że jest trafny w większości przypadków.
   Odjęcie średniej od oceny pozwala poradzić sobie z często spotykanym zjawiskiem spłaszczenia ocen (używanie przez użytkownika ocen tylko po jednej stronie skali),
   może jednak spowodować nieważność funkcji podobieństwa w przypadku gdy użytkownik ocenił tylko jeden przedmiot,
   lub wszystkie wspólnie ocenione przedmioty mają ocenę równą średniej (wtedy $S_{uv}=\frac{0}{0}$).
   Podobieństwo kosinusowe jest bardziej odporne na szczególne przypadki w danych,
   dlatego jest często wykorzystywane przy bardzo rzadkich danych (kiedy takie przypadki często występują).
   Oba podobieństwa nie sprawdzają się zbyt dobrze w przypadku gdy użytkownik wystawia wszystkim przedmiotom takie same oceny,
   oraz premiują podobieństwo pomiedzy użytkownikami z pojedynczymi wspólnie ocenionymi przedmiotami (przy jednym wspólnym przedmiocie podobieństwo kosinusowe = 1),
   dlatego, stosowane są często dodatkowe wagi ze względu na ilość wspólnie ocenionych przedmiotów lub odgraniczenia na ich minimalną ilość.
   Jeśli założenia funkcji nie są spełnione (za mało wspólnych przedmiotów), lub wartość jest bez sensu (np. $\frac{0}{0}$)
   funkcja przyjmuje wartość odpowiadającą brakowi podobieństwa (zazwyczaj 0).\newline\newline
   Do wyliczenia przewidzianej oceny przedmiotu używa się ważonej średniej z ocen wystarczająco podobnych użytkowników
   (obcięcie listy użytkowników według wartości funkcji podobieństwa, ilości najbliższych sąsiadów, lub obu), zadanej wzorem:\newline
   \begin{center}
    $r'_{u,i}=\overline{r_{u}}+\frac{\sum\limits_{v\in N_u}(r_{vi}-\overline{r_v})S_{uv}}{\sum\limits_{v\in N_u}S_{uv}}$
   \end{center}
   {\scriptsize
   $N_u$ -- zbiór sąsiadów (najbardziej podobnych użytkowników)
   }\newline
   \subsection{Rozkład według wartości osobliwych}
    Rozkład SVD (Singular Value Decomposition) macierzy $m\times n$ przedstawiony jest wzorem:
    $M=U\Sigma V^*$\newline
    gdzie $U$ -- macierz unitarna $m\times m$, $\Sigma$ -- macierz diagonalna zawierająca wartości własne macierzy $M$,
    $V$ -- macierz unitarna $n\times n$\newline
    (w przypadku macierzy nad ciałem rzeczywistym macierze unitarne są ortogonalne)\newline\newline
    Rozkład SVD stosowany jest między innymi do kompresji macierzy:\newline
    %można to zrobić jako lematy
    W przypadku gdy $m>n$ ($m<n$) $m-n$ ostatnich kolumn macierzy $U$ ($n-m$ ostatnich wierszy macierzy $V^*$) jest nieistotne,
    gdyż są mnożone zawsze przez wektor $0$, więc można ich nie przechowywać w pamięci.\newline
    Podobnie dzieje się w przypadku wierszy (kolumn) przypadających na zerowe wartości własne w macierzy $\Sigma$.\newline
    Zastosowanie jednej permutacji do wierszy macierzy $U$, kolumn macierzy $V^*$, oraz wartości własnych w macierzy $\Sigma$ nie zmienia ich iloczynu.\newline
    Po zastosowaniu tych przekształceń dla $r=$rank$(M)$ otrzymujemy rozkład $M=U'\Sigma'V'^{*}$, gdzie macierz $U'$ ma wymiary $m\times r$ $\Sigma'$
    jest macierzą diagonalną rozmiaru $r\times r$, zaś $V'^{*}$ macierzą rozmiaru $r\times n$
    (a więc rozkład pozwala na przechowywanie mniejszej ilości danych dla $r<\frac{mn}{m+n+1}$).\newline
    Norma Frobeniusa macierzy: $\lVert M \rVert_F=\sqrt{\sum\limits_{i=1}^{m}\sum\limits_{j=1}^{n}|m_{ij}|^2}$\newline
    \textbf{Twierdzenie 2.2.2.1.} (Eckhart-Young 1936) Dla dowolnego $r<$rank$(M)$
    macierz $\tilde{M}=U\Sigma_r V^*$,
    (gdzie $\Sigma_r$, to macierz $\Sigma$ z pozostawionymi jedynie $r$ wartościami własnymi o największych wartościach bezwzględnych)
    jest najlepszym przybliżeniem macierzy $M$ pod względem normy Frobeniusa, wśród macierzy o rzędzie $\le r$.\newline
    Zastosowanie rozkładu SVD i Twierdzenia Eckharta-Younga pozwala na stratną kompresję macierzy.\newline\newline
    %
    Algorytm rekomendacyjne z grupy SVD polegają na wygenerowaniu mozliwie
    najlepszych macierzy $U'$ i $V'^{*}$ dla zadanego $r$ reprezentującymi pełną macierz ocen użytkownik--przedmiot
    (wiersz zawiera oceny wystawione przez jednego użytkownika, zaś kolumna oceny wystawione jednemu przedmiotowi)
    na podstawie rzadkiej macierzy znanych już ocen.
    %być może przydałaby się unifikacja r i f -- raz rząd a raz faktor, ale tylko jedno mogłoby być czytelne
    \subsubsection{Model SVD}
     Oznaczenia:\newline
     $p_u\in\mathbb{R}^f$ -- wektor związany z użytkownikiem $u$\newline
     $b_u\in\mathbb{R}$ -- podstawa oceny związana z użytkownikiem $u$\newline
     $q_i\in\mathbb{R}^f$ -- wektor związany z przedmiotem $i$\newline
     $b_i\in\mathbb{R}$ -- podstawa oceny związana z przedmiotem $i$\newline
     $\mu$ -- średnia wszystkich ocen wystawionych wszystkim przedmiotom\newline
     $K=\{(u,i)|$ użytkownik $u$ wystawił ocenę przedmiotowi $i\}$\newline
     $\lambda_{*}$ -- różne stałe użyte do regularyzacji (ustawiane w celu optymalizacji pożądanych miar jakości predykcji)\newline 
     $r_{ui}$ -- prawdziwa ocena wystawiona przedmiotowi $i$ przez użytkownika $u$\newline
     $\tilde{r}_{ui}$ -- przewidziana przez system ocena przypisana użytkownikowi $u$ i przedmiotowi $i$\newline
     %
     \begin{center}
     $\tilde{r}_{ui}=\mu+b_u+b_i+p_u\cdot q_i$
     \end{center}
     zaś parametry ($b_*,p_*,q_*$) równań wyliczone są poprzez minimalizację funkcji kwadratowej:
     \begin{center}
     $\sum\limits_{(u,i)\in K}(r_{ui}-\mu-b_u-b_i-p_u\cdot q_i)^2+\lambda\cdot(b_u^2+b_i^2+\lVert p_u\rVert^2+\lVert q_i\rVert^2)$
     \end{center}
     Dla $f=$rank$(M)$ pierwsza część funkcji byłby zerowa dla wektorów $p$ i $q$ będących wierszami macierzy $U$ i $V$
     (macierz $\Sigma$ wmnożona w pozostałe) z rozkładu SVD macierzy $M$ (z dowolnymi wartościami zastępuącymi nieznane).
     Ustawienie $f$ na odpowiednią wielkość pozwala uzyskać z jednej strony model wystarczająco prosty do wyliczenia,
     oraz wystarczająco skomplikowany, aby wektory $p_*$ i $q_*$ mogły oddać profile użytkowników i przedmiotów.
     Wartość $f$ odpowiednio mniejsza od rank$(M)$ uniemożliwia modelowi przeuczenie się znanych ocen i powodując uproszczenie modelu
     ustala wartości $\tilde{r}_{ui}$ na najmniej komplikujące model.
     Ustawienie stałej $\lambda$ na niezerową pozwala uniknąć optymalizacji funkcji w skrajnych, oddalonych wartościach wektorów
     (co mogłoby wynikać z zaburzeń w danych).
    \subsubsection{Algorytm SVD++}
     Najczęściej uzywanym rozszerzeniem modelu SVD jest algorytm SVD++, korzystający również z informacji implicite.
     Do modelu dodane zostają wektory $y_i\in\mathbb{R}^f$ reprezentujące informacje o użyciach przedmiotów.
     Równanie docelowe przyjmuje postać:
     \begin{center}
      $\tilde{r}_{ui}=\mu+b_u+b_i+q_i\cdot\left(p_u +|N(u)|^{-\frac{1}{2}}\sum\limits_{j\in N(u)}y_j\right)$
     \end{center}
     gdzie $N(u)$ oznacza zbiór przedmiotów ocenionych przez użytkownika $u$.\newline
     {\scriptsize
      (dodawanie wektorów oznacza dodanie wyraz po wyrazie, zaś mnożenie iloczyn skalarny)
     }\newline
     Parametry równań znajdowane są poprzez optymalizację modelu w procesie iteracyjnym opisanym pseudokodem:\newline\newline
     %
    \hspace*{16pt}	for $I$ iterations\{\newline
    \hspace*{32pt}		foreach $(u,i)\in K$\{\newline
    \hspace*{48pt}			$py=p_u +|N(u)|^{-\frac{1}{2}}\cdot\sum\limits_{j\in N(u)}y_j$\newline
    \hspace*{48pt}			$\tilde{r}_{ui}=\mu+b_u+b_i+q_i\cdot py$\newline
    \hspace*{48pt}			$err=\tilde{r}_{ui}-r_{ui}$\newline
    \hspace*{48pt}			$b_u=b_u+\alpha\cdot(err-\lambda_1\cdot b_u)$\newline
    \hspace*{48pt}			$b_i=b_i+\alpha\cdot(err-\lambda_2\cdot b_i)$\newline
    \hspace*{48pt}			$p_u=p_u+\alpha\cdot(err\cdot q_i-\lambda_3\cdot p_u)$\newline
    \hspace*{48pt}			$q_i=q_i+\alpha\cdot(err\cdot py-\lambda_4\cdot q_i)$\newline
    \hspace*{48pt}			foreach $j\in N(u)$\{\newline
    \hspace*{64pt}				$y_j=y_j+\alpha\cdot(err\cdot |N(u)|^{-\frac{1}{2}}\cdot q_i-\lambda_5\cdot y_j)$\newline
    \hspace*{48pt}			\}\newline
    \hspace*{32pt}		\}\newline
    \hspace*{16pt}	\}\newline
     {\scriptsize
      stała $\alpha$ oznacza szybkość uczenia (powinna więc zależeć od ilości przewidzianych iteracji = dostępnego czasu na działanie algorytmu uczącego)\newline
      stałe $\lambda_*$ służą lepszemu dostosowaniu algorytmu do problemu i powinny zostać ustalone tak, by optymalizowały funkcje oceny na zbiorze testowym\newline
      wartości początkowe wektorów $p_*$ i $y_*$ powinny zostać wylosowane np. z rozkładu normalnego
      (jeśli wszystkie wektory początkowe mają wartość $0$ na tej samej współrzędnej to tak pozostanie,
      jeśli wszystkie wektory mają te same wartości na określonych współrzędnych, to nie będą mogły się zróżnicować i będą redundantne)
     }\newline

     
  %TODO wspomnieć, że mogą być oceny poza zakresem 
  
   \subsection{Spersonalizowany ranking Bayesa}
    W przypadku dostępu do danych wyłącznie typu implicite popularną metodą tworzenia spersonalizowanych list rekomendacyjnych jest
    faktoryzacja macierzy oparta o analizę bayesowską prawdopodobieństw.\newline
    Mając dostępną binarną macierz użyć przedmiotów traktujemy negatywne wartości bardziej jako wartość nieznaną niż jako stwierdzenie,
    że dany przedmiot nie podobał się użytkownikowi. Aby uzyskać więcej niż dwie wartości, a przez to i rozróżnienie w obrębie przedmiotów nieznanych
    model BPR (Bayesian personalized ranking) stara się oszacować dla danego użytkownika i każdej pary przedmiotów prawdopodobieństwo,
    że preferuje on pierwszy z nich. Aby uzystać początkowe dane używane do filtrowania kolaboratywnego pomiedzy użytkownikami
    przyjmujemy, że te już użyte są bardziej preferowane od nieznanych i dla każdego wiersza macierzy tworzymy nową macierz kwadratową.
    \begin{multicols}{3}
     \begin{tabular}{c|c|c|c|c|c|}
       & i1 & i2 & i3 & i4 & i5 \\
      \hline
      u1 & + & ? & ? & ? & + \\
      \hline
      u2 & ? & ? & + & ? & + \\    
      \hline
      u3 & + & + & + & ? & ? \\    
      \hline
      u4 & ? & ? & ? & ? & + \\    
     \end{tabular}
     \begin{center}
      \includegraphics[scale=0.72]{strzalka.jpg}\newline
      %TODO zmienić tę strzałkę tak żeby wskazywała z wiersza u2, być może jakieś rozszerzenie zamiast strzałki
      $i>_{u_2}j$
     \end{center}
     \begin{tabular}{c|c|c|c|c|c|}
       & j1 & j2 & j3 & j4 & j5 \\
      \hline
      i1 & X & ? & - & ? & - \\
      \hline
      i2 & ? & X & - & ? & - \\    
      \hline
      i3 & + & + & X & + & ? \\    
      \hline
      i4 & ? & ? & - & X & - \\
      \hline
      i5 & + & + & ? & + & X \\ 
     \end{tabular}
    \end{multicols}
    Decyzję o tym czy przedmiot $i$ jest bardziej pasujący do użytkownika $u$ od przedmiotu $j$ jest podejmowana na podstawie prawdopodobieństwa warunkowego
    $\mathbb{P}(i>_u j|\Theta)$, gdzie $\Theta$ jest modelem wygenerowanym przez algorytm.
    Podobnie jak w przypadku modelu SVD $\Theta$ składa się z wektorów
    $p_u,q_i\in\mathbb{R}^f$ oraz wartości $b_i\in\mathbb{R}$, oraz powstaje poprzez iterowaną
    optymalizację funkcji celu:
    \begin{center}
     $\sum\limits_{(u,i,j)\in D_K}\ln{(\sigma(\tilde{s}_{uij}))}-\lambda\lVert\Theta\rVert^2$
    \end{center}
    gdzie $D_K=\{(u,i,j):i\in N(u) \& j\notin N(u)\}, \tilde{s}_{u,i,j}=\tilde{r}_{ui}-\tilde{r}_{uj}, \lVert\Theta\rVert^2=(b_i^2+\lVert p_u\rVert^2+\lVert q_i\rVert^2)$,
    $\sigma(x)=\frac{1}{1+e^{-x}}$\newline
    Zaś przewidywana ocena przedmiotu (opisująca wyłącznie kolejność preferencji) jest równa $\tilde{r}_{ui}=b_i+p_u\cdot q_i$
    ($\mu$ oraz $b_u$ nie mają tutaj sensu)\newline
    Algorytm iterowanego poprawiania modelu wygląda podobnie do tego z SVD:\newline\newline
    %
    \hspace*{16pt}	for $I$ iterations\{\newline
    \hspace*{32pt}		wylosuj $(u,i,j)$ z $D_K$\{\newline   
    \hspace*{48pt}			$\tilde{s}=b_i-b_j+p_u\cdot(q_i-q_j)$\newline
    \hspace*{48pt}			$err=\frac{e^{-\tilde{s}}}{1+e^{-\tilde{s}}}$\newline
    \hspace*{48pt}			$b_i=b_i+\alpha\cdot(err-\lambda_2\cdot b_i)$\newline
    \hspace*{48pt}			$b_j=b_j+\alpha\cdot(-err-\lambda_2\cdot b_j)$\newline
    \hspace*{48pt}			$p_u=p_u+\alpha\cdot(err\cdot (q_i-q_j)-\lambda_3\cdot p_u)$\newline
    \hspace*{48pt}			$q_i=q_i+\alpha\cdot(err\cdot p_u-\lambda_4\cdot q_i)$\newline
    \hspace*{48pt}			$q_j=q_j+\alpha\cdot(-err\cdot p_u-\lambda_4\cdot q_j)$\newline
    \hspace*{32pt}		\}\newline
    \hspace*{16pt}	\}\newline
    %TODO czy za każdym razem pisać definicje zmiennych czy raz wystarczy (zalezy czy ktoś czyta wyrywkowo czy całość)
    W tym algorytmie trójki $(u,i,j)\in D_K$ są wybierane losowo, gdyż jest ich na ogół o wiele wiecej niż par $(u,i)\in K$
    i przez to już jedna iteracja po wszystkich mogła by być zbyt droga obliczeniowo.
   
  \section{Filtrowanie na podstawie opisów} %TODO jakieś lepsze tłumaczenie

\begin{thebibliography}{99}%TODO
\addcontentsline{toc}{chapter}{Bibliografia}






\end{thebibliography}

\end{document}